---
title: "[TIL] NLP Overview"
excerpt: ""
categories:
  - TIL
tags:
  - 

toc: true
toc_sticky: true
---

# NLP overview

- NLU와 NLG task로 분류됨.
- ACL, EMNLP, NAACL 학회가 있음.
- low-level parsing
    - 쪼개진 단어를 tokenization이라 함.
    - stemming 어미의 변화가 다양하지만 같은 단어라고 어근을 추출하는 것을 말함.
- Word and phrase level
    - NER : NewYork Times를 한 단어라고 판단해야함.
    - POS : 단어의 개체명을 인식함.
- Sentence level
    - 감정분석, 기계번역 등을 말함.

- Multi-sentence and paragraph level
    - Entailment prediction, question answering, dialog systems, summarization가 있음.
    - Entailment prediction : 두 문장간 관계 예측.
    - question answering 구글 검색 했을 때 답을 제공.
    - dialog systems : 챗봇
    - summarization : 자동 요약

- Text mining
    - KDD, The WebConf, WSDM, CIKM, ICWSM

- Information retrieval
    - 검색 기능과 관련된 내용

## Trends of NLP

- 주어진 텍스트 데이터를 단어단위로 분리하고 각 단어를 특정 차원을 가진 벡터로 표현함. -> word embedding

- sequence는 순서 정보를 가지고 있음.

- sequence를 다루는 rnn이 핵심 모델로 자리잡음.

- LSTM, GRU가 사용 됨.

- 2017년 구글이 attention is all you need를 발표. rnn을 self-attention으로 대체, Transformer

- Transformer는 기계 번역을 위해 나온 모델이었음.

- 예전에는 주로 rule 기반 예측을 함. rnn 모델을 사용하니 성능이 올라감.

- 다양한 분야로 적용됨.

- self-attention 모듈을 많이 쌓고 이 모델을 많은 text 데이터로 학습함. -> 큰 구조변경 없이 전이학습을 통해 발전을 함.

- BERT, GPT-2, GPT-3로 발전 함.

# Bag-of-Words

`"John really really loves this movie","Jane really likes this song"`     
`Vocabularay : {"John","really","loves","this","movie","Jane","likes","song"}`  
- 단어 집합이 만들어지며 이때 같은 단어는 한번만 만듦.  
- 각 단어를 단어집합의 크기인 8을 차원으로 가지는 one-hot-vector를 만듦.  
John: [1 0 0 0 0 0 0 0]  
really: [0 1 0 0 0 0 0 0]  
loves: [0 0 1 0 0 0 0 0]  
this: [0 0 0 1 0 0 0 0]  
movie: [0 0 0 0 1 0 0 0]  
Jane: [0 0 0 0 0 1 0 0]  
likes: [0 0 0 0 0 0 1 0]  
song: [0 0 0 0 0 0 0 1]

- 두 단어의 유클리디안 거리는 sqrt(2)
- 코사인 유사도는 0
- 단어의 의미 상관없이 모두 동일한 관계를 가짐.

- 문장은 각 단어의 one-hot vector를 더해서 표현가능. -> Bag of Words Vector라 부름.  

## NaiveBayes Classifier  

![Bag of Words](..\images\naivebayes_classifier.JPG)

- P(d|c) 클래스 c가 주어졌을 때 d가 나올 확률
- P(d)는 상수로 생략 가능
  
![Bag of Words](..\images\classifier.JPG)

![Bag of Words](..\images\document.JPG)

- CV 클래스일 확률은 1/2 NLP 클래스일 확률 1/2

![Bag of Words](..\images\word.JPG)

- CV 클래스 전체 단어는 14개 NLP 클래스 전체 단어 10개
- test document의 각 단어가 각 클래스가 주어졌을 때 나올 확률을 구함.
- 그리고 각 단어가 나올 확률과 사전 확률인 클래스 확률을 곱해서 클래스를 분류함.

## PyThon 형태소 분석기

### konlpy.tag 통계 기반 형태소 분석기

```python
from konlpy.tag import Hannanum
hannanum = Hannanum()
text = '환영합니다! 자연어 처리 수업은 재미있게 듣고 계신가요?'
print(hannanum.morphs(text))  # 형태소 단위로 나누기 
print(hannanum.nouns(text))   # 명사만 뽑아내기
print(hannanum.pos(text))     # 품사 태깅

['환영', '하', 'ㅂ니다', '!', '자연어', '처리', '수업', '은', '재미있', '게', '듣', '고', '계시', 'ㄴ가', '요', '?']
['환영', '자연어', '처리', '수업']
[('환영', 'N'), ('하', 'X'), ('ㅂ니다', 'E'), ('!', 'S'), ('자연어', 'N'), ('처리', 'N'), ('수업', 'N'), ('은', 'J'), ('재미있', 'P'), ('게', 'E'), ('듣', 'P'), ('고', 'E'), ('계시', 'P'), ('ㄴ가', 'E'), ('요', 'J'), ('?', 'S')]
```
```python
from konlpy.tag import Kkma
kkma = Kkma()
text = '환영합니다! 자연어 처리 수업은 재미있게 듣고 계신가요?'
print(kkma.morphs(text))  # 형태소 단위로 나누기 
print(kkma.nouns(text))   # 명사만 뽑아내기 
print(kkma.pos(text))     # 품사 태킹

['환영', '하', 'ㅂ니다', '!', '자연어', '처리', '수업', '은', '재미있', '게', '듣', '고', '계시', 'ㄴ가요', '?']
['환영', '자연어', '처리', '수업']
[('환영', 'NNG'), ('하', 'XSV'), ('ㅂ니다', 'EFN'), ('!', 'SF'), ('자연어', 'NNG'), ('처리', 'NNG'), ('수업', 'NNG'), ('은', 'JX'), ('재미있', 'VA'), ('게', 'ECD'), ('듣', 'VV'), ('고', 'ECE'), ('계시', 'VXA'), ('ㄴ가요', 'EFQ'), ('?', 'SF')]
```

[konlpy 형태소 분석기 속도, 성능 비교](https://konlpy.org/ko/latest/morph/#comparison-between-pos-tagging-classes)

### 카카오 CNN 기반 형태소 분석기

```python
!git clone https://github.com/kakao/khaiii.git
!pip install cmake
!mkdir build
!cd build && cmake ../khaiii
!cd build && make all
!cd build && make resource
!cd build && make install
!cd build && make package_python
!pip install build/package_python

from khaiii import KhaiiiApi
khaiiApi = KhaiiiApi()

tokenized = khaiiApi.analyze('환영합니다! 자연어 처리 수업은 재미있게 듣고 계신가요?')
tokens = []
for word in tokenized:
  tokens.extend([str(m).split('/')[0] for m in word.morphs])
print(tokens)
```

### 띄어쓰기 pykospacing

```python
!pip install git+https://github.com/haven-jeon/PyKoSpacing.git

sent = '환영합니다! 자연어 처리 수업은 재미있게 듣고 계신가요?'
new_sent = sent.replace(" ", '') # 띄어쓰기가 없는 문장으로 만들기

from pykospacing import Spacing
spacing = Spacing()
kospacing_sent = spacing(new_sent) 

print('띄어쓰기가 없는 문장 :\n', new_sent) 
print('정답 문장:\n', sent) 
print('띄어쓰기 교정 후:\n', kospacing_sent)

띄어쓰기가 없는 문장 :
 환영합니다!자연어처리수업은재미있게듣고계신가요?
정답 문장:
 환영합니다! 자연어 처리 수업은 재미있게 듣고 계신가요?
띄어쓰기 교정 후:
 환영합니다! 자연어 처리 수업은 재미있게 듣고 계신 가요?
```

### 맞춤법 검사 Py-Hanspell

```python
# 한국어 맞춤법 검사기 기반 제작
!pip install git+https://github.com/ssut/py-hanspell.git

from hanspell import spell_checker

sent = "맞춤법 틀리면 외 않되? 쓰고싶은대로쓰면돼지 "
spelled_sent = spell_checker.check(sent)

hanspell_sent = spelled_sent.checked
print(hanspell_sent)

맞춤법 틀리면 왜 안돼? 쓰고 싶은 대로 쓰면 되지
```





