---
title: "[TIL PyTorch] Multi-gpu 사용"
excerpt: ""
categories:
  - TIL
tags:
  - 

toc: true
toc_sticky: true
--- 

# Multi-GPU 다루기

## 개념정리

- Single vs Multi : 한개를 쓰냐 두개를 쓰냐
- GPU vs Node : Node는 system 즉 컴퓨터 Node의 GPU를 사용
- Single Node Single GPU : 한대의 컴퓨터 내 한개의 GPU 사용.
- Single Node Multi GPU : 한개 컴퓨터 내 여러개 GPU 사용 최대 8개까지
- Multi Node Multi GPU : 서버실

    > Multi Node Multi GPU는 사실상 어려움. 따라서 Single Node Multi GPU를 주로 사용함.

## Model parallel

- 다중 GPU로 학습할 때 분산하는 두가지 방법.

    - 모델 나누기 / 데이터 나누기.

- 모델을 나누는 것은 예전부터 사용 ex) alexnet

- 모델의 병목, 파이프라인의 어려움 등으로 인해 모델 병렬화는 고난이도 과제

- 병렬화를 잘 시켜야함. 두 GPU가 따로 일을 하면 두개의 GPU를 사용하는 이유가 없음.

## Data parallel

- 데이터를 나눠 GPU 할당후 결과의 평균을 취하는 방법.

- minibatch 수식과 유사한데 한번에 여러 GPU에서 수행.
- PyTorch에서는 아래 두 가지 방식을 제공

    - DataParallel, DistributedDataParallel

- DataParallel : 단순히 데이터를 분배한 후 평균을 취함.

    -> GPU 사용 불균형 문제 발생, Batch 사이즈 감소 (한 GPU가 병목)

- DistributedDataParallel - 각 CPU마다 process 생성하여 개별 GPU로 할당.

    -> 기본적으로 DataParallel로 하나 개별적으로 연산의 평균을 냄.

